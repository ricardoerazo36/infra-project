# ğŸ“° Pipeline de AnÃ¡lisis de Noticias y CorrelaciÃ³n con COLCAP

## ğŸ‘¥ Integrantes del Grupo

| Nombre | CÃ³digo | Correo |
|--------|--------|--------|
| Ricardo Erazo MuÃ±oz | 2242117 | ricardo.erazo@correounivalle.edu.co |
| Heidy Gelpud | 2242550 | heidy.gelpud@correounivalle.edu.co |
| James Calero | 2243461 | james.calero@correounivalle.edu.co |

---

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un **pipeline de datos completo** que recolecta noticias de Colombia, las procesa, analiza y correlaciona con el comportamiento del Ã­ndice bursÃ¡til **COLCAP** de la Bolsa de Valores de Colombia.

### Â¿QuÃ© hace el sistema?

Imagina que tienes un equipo de analistas trabajando 24/7:

1. **ğŸ“¥ Descargador**: Como un lector que revisa periÃ³dicos constantemente, descarga noticias de fuentes RSS colombianas (El Tiempo, Portafolio, El Espectador).

2. **ğŸ”„ Procesador**: Limpia y organiza las noticias, como un editor que quita el "ruido" (HTML, caracteres raros) y deja solo el contenido importante.

3. **ğŸ“Š Analizador**: Clasifica cada noticia por tema (economÃ­a, seguridad, polÃ­tica, salud), como un archivista que organiza documentos por categorÃ­as.

4. **ğŸ’¹ Recolector EconÃ³mico**: Obtiene el valor actual del COLCAP usando la API de Gemini (IA de Google), como un analista financiero consultando la bolsa.

5. **ğŸ”— Correlador**: El "cerebro" del sistema - busca patrones entre las noticias y el mercado. Â¿MÃ¡s noticias de seguridad = cambio en el COLCAP?

6. **ğŸ“ˆ Dashboard**: Una interfaz web donde puedes ver todos los resultados de forma visual.

7. **ğŸŒ Common Crawl**: Fuente adicional que obtiene noticias histÃ³ricas de archivos web masivos.

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FUENTES DE DATOS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“¡ RSS Feeds          ğŸŒ Common Crawl         ğŸ’¹ Gemini API    â”‚
â”‚  (El Tiempo, etc.)     (Archivo histÃ³rico)     (Datos COLCAP)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                     â”‚
         â–¼                       â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DOWNLOADER    â”‚    â”‚  COMMONCRAWL    â”‚    â”‚  ECONOMIC_DATA  â”‚
â”‚   (RSS Parser)  â”‚    â”‚   (Fetcher)     â”‚    â”‚   (Collector)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚                      â”‚
         â–¼                      â–¼                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚              data/raw/                   â”‚           â”‚
â”‚         (Noticias sin procesar)          â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                 â”‚                                     â”‚
                 â–¼                                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚             PROCESSOR                    â”‚           â”‚
â”‚      (Limpieza y normalizaciÃ³n)          â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                 â”‚                                     â”‚
                 â–¼                                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚             data/clean/                  â”‚           â”‚
â”‚         (Noticias procesadas)            â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                 â”‚                                     â”‚
                 â–¼                                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚              ANALYZER                    â”‚           â”‚
â”‚     (ClasificaciÃ³n por categorÃ­as)       â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                 â”‚                                     â”‚
                 â–¼                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CORRELATOR                               â”‚
â”‚            (AnÃ¡lisis estadÃ­stico de correlaciones)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          DASHBOARD                               â”‚
â”‚                    (VisualizaciÃ³n Web)                           â”‚
â”‚                    http://localhost:8080                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| Componente | TecnologÃ­a | PropÃ³sito |
|------------|------------|-----------|
| Backend | Python 3.10 | LÃ³gica de procesamiento |
| Contenedores | Docker & Docker Compose | OrquestaciÃ³n de servicios |
| OrquestaciÃ³n K8s | Kubernetes (Minikube) | Despliegue escalable |
| API IA | Google Gemini | ObtenciÃ³n de datos financieros |
| Dashboard | Flask + Chart.js | VisualizaciÃ³n web |
| AnÃ¡lisis | NumPy, Pandas | CÃ¡lculos estadÃ­sticos |

---

## ğŸ“ Estructura del Proyecto

```
proyecto/
â”œâ”€â”€ ğŸ“„ docker-compose.yml      # OrquestaciÃ³n de contenedores
â”œâ”€â”€ ğŸ“„ deploy.sh               # Script de despliegue Docker
â”œâ”€â”€ ğŸ“„ deploy-k8s.sh           # Script de despliegue Kubernetes
â”œâ”€â”€ ğŸ“„ .env                    # Variables de entorno (API Keys)
â”‚
â”œâ”€â”€ ğŸ“ downloader/             # Servicio de descarga RSS
â”‚   â”œâ”€â”€ main_loop.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ processor/              # Servicio de procesamiento
â”‚   â”œâ”€â”€ main_loop.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ analyzer/               # Servicio de anÃ¡lisis temÃ¡tico
â”‚   â”œâ”€â”€ main_loop.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ economic_data/          # Recolector de datos econÃ³micos
â”‚   â”œâ”€â”€ main_loop.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ correlator/             # Servicio de correlaciÃ³n
â”‚   â”œâ”€â”€ main_loop.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ dashboard/              # Interfaz web
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ commoncrawl/            # Fetcher de Common Crawl
â”‚   â”œâ”€â”€ main_loop.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ k8s/                    # Manifiestos de Kubernetes
â”‚   â”œâ”€â”€ namespace.yml
â”‚   â”œâ”€â”€ pvc.yml
â”‚   â”œâ”€â”€ secret-gemini.yml
â”‚   â”œâ”€â”€ deployment-*.yml
â”‚   â””â”€â”€ services.yml
â”‚
â””â”€â”€ ğŸ“ data/                   # Datos generados (volumen)
    â”œâ”€â”€ raw/                   # Noticias descargadas
    â”œâ”€â”€ clean/                 # Noticias procesadas
    â”œâ”€â”€ analysis/              # Conteos por categorÃ­a
    â”œâ”€â”€ economic/              # Datos del COLCAP
    â”œâ”€â”€ results/               # Correlaciones calculadas
    â””â”€â”€ commoncrawl/           # Datos de Common Crawl
```

---

## ğŸš€ Instrucciones de InstalaciÃ³n y EjecuciÃ³n

### Prerrequisitos

Antes de comenzar, asegÃºrate de tener instalado:

- **Docker** (versiÃ³n 20.10 o superior)
- **Docker Compose** (versiÃ³n 2.0 o superior)
- **Git** (para clonar el repositorio)

Para verificar las instalaciones:

```bash
docker --version
docker-compose --version
git --version
```

### OpciÃ³n 1: Despliegue con Docker Compose

Esta es la forma mÃ¡s sencilla de ejecutar el proyecto.

#### Paso 1: Clonar el repositorio

```bash
git clone https://github.com/ricardoerazo36/infra-project.git
```

#### Paso 2: Configurar la API Key de Gemini

El proyecto usa la API de Google Gemini para obtener datos del COLCAP. Ya viene configurada una API Key de prueba.

#### Paso 3: Ejecutar el despliegue

```bash
# Dar permisos de ejecuciÃ³n al script
chmod +x deploy.sh

# Ejecutar el despliegue
./deploy.sh
```

O manualmente:

```bash
# Crear directorios de datos
mkdir -p data/{raw,clean,analysis,economic,results,commoncrawl}

# Construir las imÃ¡genes
docker-compose build

# Iniciar todos los servicios
docker-compose up -d
```

#### Paso 4: Verificar que todo estÃ© funcionando

```bash
# Ver el estado de los contenedores
docker-compose ps

# Ver los logs en tiempo real
docker-compose logs -f

# Ver logs de un servicio especÃ­fico
docker-compose logs -f downloader
```

#### Paso 5: Acceder al Dashboard

Abre tu navegador y visita:

```
http://localhost:8080
```

ğŸ‰ Â¡Listo! El sistema comenzarÃ¡ a recolectar noticias automÃ¡ticamente.

---

### OpciÃ³n 2: Despliegue con Kubernetes (Minikube)

Para un despliegue mÃ¡s robusto y escalable.

#### Prerrequisitos adicionales

```bash
# Instalar Minikube
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube

# Instalar kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install kubectl /usr/local/bin/kubectl
```

#### Paso 1: Iniciar Minikube

```bash
# Iniciar el cluster
minikube start --driver=docker --memory=4096 --cpus=2

# Verificar que estÃ© funcionando
kubectl cluster-info
```

#### Paso 2: Ejecutar el despliegue

```bash
# Dar permisos de ejecuciÃ³n
chmod +x deploy-k8s.sh

# Ejecutar el despliegue en Kubernetes
./deploy-k8s.sh
```

#### Paso 3: Acceder al Dashboard

```bash
# Crear un tÃºnel para acceder al dashboard
kubectl port-forward svc/dashboard-svc 8080:8080 -n news-pipeline

# Abrir en el navegador
# http://localhost:8080
```

#### Comandos Ãºtiles de Kubernetes

```bash
# Ver todos los pods
kubectl get pods -n news-pipeline

# Ver logs de un pod
kubectl logs -f <nombre-del-pod> -n news-pipeline

# Ver servicios
kubectl get svc -n news-pipeline

# Escalar un deployment
kubectl scale deployment news-processor --replicas=3 -n news-pipeline

# Eliminar todo el despliegue
kubectl delete namespace news-pipeline
```

---

## ğŸ“Š Uso del Dashboard

Una vez que el sistema estÃ© funcionando, el Dashboard te mostrarÃ¡:

### Panel Principal

1. **Estado del Sistema**: Indica si todos los servicios estÃ¡n operativos.

2. **Correlaciones Detectadas**: Muestra la relaciÃ³n entre cada categorÃ­a de noticias y el COLCAP:
   - ğŸŸ¢ **Verde (positiva)**: MÃ¡s noticias de este tema = COLCAP sube
   - ğŸ”´ **Rojo (negativa)**: MÃ¡s noticias de este tema = COLCAP baja
   - ğŸŸ¡ **Amarillo (neutral)**: No hay correlaciÃ³n clara

3. **Insights**: Interpretaciones automÃ¡ticas de los datos.

4. **GrÃ¡fico de EvoluciÃ³n**: Muestra la cantidad de noticias por tema a lo largo del tiempo.

## âš™ï¸ ConfiguraciÃ³n y PersonalizaciÃ³n

### Variables de Entorno

| Variable | DescripciÃ³n | Valor por defecto |
|----------|-------------|-------------------|
| `GEMINI_API_KEY` | API Key de Google Gemini | (requerida) |
| `SLEEP_INTERVAL` | Intervalo entre ejecuciones (segundos) | VarÃ­a por servicio |

### Intervalos por Servicio

| Servicio | Intervalo | DescripciÃ³n |
|----------|-----------|-------------|
| Downloader | 1 hora | Descarga nuevas noticias |
| Processor | 30 min | Procesa noticias pendientes |
| Analyzer | 30 min | Analiza y clasifica |
| Economic Data | 1 hora | Actualiza COLCAP |
| Correlator | 1 hora | Calcula correlaciones |
| Common Crawl | 24 horas | Busca en archivo histÃ³rico |

## ğŸ”§ Comandos Ãštiles

### Docker Compose

```bash
# Iniciar todos los servicios
docker-compose up -d

# Detener todos los servicios
docker-compose down

# Ver logs de todos los servicios
docker-compose logs -f

# Ver logs de un servicio especÃ­fico
docker-compose logs -f analyzer

# Reiniciar un servicio
docker-compose restart correlator

# Reconstruir y reiniciar
docker-compose up -d --build

# Ver uso de recursos
docker stats
```

### Inspeccionar Datos

```bash
# Ver noticias descargadas
ls -la data/raw/

# Ver noticias procesadas
ls -la data/clean/

# Ver anÃ¡lisis por dÃ­a
cat data/analysis/daily_counts.json

# Ver datos del COLCAP
cat data/economic/colcap_historical.json

# Ver correlaciones
cat data/results/correlations_latest.json
```

---

## ğŸ› SoluciÃ³n de Problemas

### El Dashboard no carga datos

**SÃ­ntoma**: El dashboard muestra "Sistema iniciÃ¡ndose..."

**SoluciÃ³n**: 
1. Espera unos minutos, el sistema necesita tiempo para recolectar datos.
2. Verifica que los servicios estÃ©n corriendo:
   ```bash
   docker-compose ps
   ```

### Error de conexiÃ³n con Gemini

**SÃ­ntoma**: Logs muestran "Error de conexiÃ³n con Gemini"

**SoluciÃ³n**:
1. Verifica tu API Key en `.env`
2. Verifica tu conexiÃ³n a internet
3. El sistema usarÃ¡ valores de respaldo automÃ¡ticamente

### Contenedor se reinicia constantemente

**SÃ­ntoma**: Un contenedor aparece en estado "Restarting"

**SoluciÃ³n**:
```bash
# Ver logs del contenedor problemÃ¡tico
docker-compose logs <nombre_servicio>

# Reiniciar el servicio
docker-compose restart <nombre_servicio>
```

### Espacio en disco

**SÃ­ntoma**: El sistema deja de funcionar por falta de espacio

**SoluciÃ³n**:
```bash
# Limpiar datos antiguos
rm -rf data/raw/*.json
rm -rf data/clean/*.json

# Limpiar imÃ¡genes Docker no usadas
docker system prune -a
```

---

## ğŸ“ˆ MÃ©tricas y Monitoreo

### Ver EstadÃ­sticas del Sistema

```bash
# Uso de CPU y memoria por contenedor
docker stats

# Cantidad de archivos procesados
find data/clean -name "*.json" | wc -l

# Ver las Ãºltimas correlaciones
cat data/results/correlations_latest.json | python -m json.tool
```
</div>
